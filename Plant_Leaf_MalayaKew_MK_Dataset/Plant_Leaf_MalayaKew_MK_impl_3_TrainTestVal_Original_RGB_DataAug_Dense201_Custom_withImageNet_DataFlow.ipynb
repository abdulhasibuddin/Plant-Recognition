{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Plant_Leaf_MalayaKew_MK_impl_3_TrainTestVal_Original_RGB_DataAug_Dense201_Custom_withImageNet_DataFlow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w35zPOcMyNwJ",
        "outputId": "349f2a0c-55b2-4857-c11b-f51ae1b32ccc"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph-qNIaajXGT"
      },
      "source": [
        "#drive.flush_and_unmount(timeout_ms=24)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xc7MvTxyQd7"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "#os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from IPython.display import display\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import optimizers\n",
        "#from sklearn.metrics import classification_report, confusion_matrix\n",
        "import sklearn\n",
        "import seaborn as sn\n",
        "from keras.callbacks import CSVLogger, LambdaCallback\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLy6y_e1yQhC"
      },
      "source": [
        "base_dir = 'drive/My Drive/Plant_Leaf_MalayaKew_MK_Dataset/MK/D2/'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train_patch')\n",
        "test_dir = os.path.join(base_dir, 'test_patch')\n",
        "\n",
        "work_dir = \"drive/My Drive/Plant_Leaf_MalayaKew_MK_Dataset/Records/\"\n",
        "color_type = 'rgb' # rgb, grayscale\n",
        "BATCH_SIZE = 16"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnYytOrbKGMH"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   width_shift_range=0.2, \n",
        "                                   height_shift_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   validation_split=0.2\n",
        "                                   ) \n",
        "val_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                validation_split=0.2\n",
        "                                )\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mgmPRJEKk3r"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rga2byZPKPQt",
        "outputId": "2ebddf1d-f84d-4974-921e-09c5d77ad8ed"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        color_mode=color_type, # grayscale, rgb\n",
        "        class_mode='categorical',\n",
        "        subset='training'\n",
        "        ) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 27764 images belonging to 44 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwy6M8sgK1KT",
        "outputId": "479faf29-4ea6-45a5-bcc6-bca1aafc2069"
      },
      "source": [
        "num_classes = train_generator.num_classes\n",
        "total_train_data = train_generator.samples\n",
        "\n",
        "print(f\"total_train_data = {total_train_data}\")\n",
        "print(f\"train_generator.image_shape = {train_generator.image_shape}\")\n",
        "print(f\"num_classes = {num_classes}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_train_data = 27764\n",
            "train_generator.image_shape = (256, 256, 3)\n",
            "num_classes = 44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZXBvsZ5aYBq",
        "outputId": "7cd1ddfe-2b36-4c6c-bfff-f277bec3a789"
      },
      "source": [
        "val_generator = val_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        color_mode=color_type, # grayscale, rgb\n",
        "        class_mode='categorical',\n",
        "        subset='validation'\n",
        "        )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6908 images belonging to 44 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvs1SpWXaYH4",
        "outputId": "0fbf732e-5ecd-4467-cb6e-d43e6e1a33fe"
      },
      "source": [
        "total_val_data = val_generator.samples\n",
        "print(f\"total_val_data = {total_val_data}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_val_data = 6908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsvrZgrALXMl",
        "outputId": "2c2dee68-72fb-40a1-f957-9bd808f604af"
      },
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        color_mode=color_type, # grayscale, rgb\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8800 images belonging to 44 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxU0D6TuOOOL",
        "outputId": "ffa3a9f1-2cb0-4583-a5fd-4035bf4331e5"
      },
      "source": [
        "total_test_data = test_generator.samples\n",
        "print(f\"total_test_data = {total_test_data}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total_test_data = 8800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roidu5RmFRJq"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRwynF9xPBWy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "53020a28-9d90-468f-d743-f58113ed7b34"
      },
      "source": [
        "# DenseNet121 ResNet101 ResNet50 DenseNet201 InceptionV3 Xception NASNetLarge ResNet152V2 InceptionResNetV2 EfficientNetB7\n",
        "impl_type = \"TL.3D.DenseNet201\" # TransferLearning3D \n",
        "dataset = f\"MalayaKew.D2.TTV.{color_type}.{train_generator.image_shape[1]}p.DataAug.DataFlow\" # +str(img_size)+\"p\"\n",
        "dataset"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'MalayaKew.D2.TTV.rgb.256p.DataAug.DataFlow'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLVsewD-O3gl"
      },
      "source": [
        "#'''\n",
        "count_no_improvement = 0\n",
        "epoch_initial = True\n",
        "#'''"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxppPm7hO3l8",
        "outputId": "998817d6-8dc5-46a3-e990-9599e0d57667"
      },
      "source": [
        "#NUM_NEURONS = 16\n",
        "#NUM_LAYERS = 3\n",
        "#BATCH_SIZE = 16 # 10\n",
        "NUM_EPOCHS = 25 #300\n",
        "epochs_completed = 0\n",
        "LEARNING_RATE = 0.00001\n",
        "EPSILON = 1e-4\n",
        "early_stop_after_epochs = 5\n",
        "DROPOUT = 0.5 # 0.5 0.0\n",
        "pad = 0\n",
        "\n",
        "LOSS = 'categorical_crossentropy'\n",
        "ACTIVATION_FUNCTION = 'elu' # relu sigmoid elu\n",
        "FINAL_ACTIVATION_FUNCTION = 'softmax'\n",
        "validation_split = 0.1\n",
        "kernel_size=(1,1)\n",
        "pointTrainableAfter = \"allDefault\" # \"allDefault\" 160 170\n",
        "OPTIMIZER = \"Adam\" # Adam SGD RMSProp\n",
        "init_weights = \"imagenet\" # \"imagenet\" None\n",
        "modelExt = \".Dense.1024.1024.2048\" # .Dense.128.256.512, .512.512.512 .Dense.512.512.512.512.Res\n",
        "l2_val = 0.001\n",
        "\n",
        "# +\"_kernel\"+str(kernel_size)+\"_lr\"+str(LEARNING_RATE)+\"_batch\"+str(BATCH_SIZE)+\"_epochs\"+str(NUM_EPOCHS)\n",
        "#checkpointer_name  = \"weights_\"+dataset+\"_\"+impl_type+\"_nLayers\"+str(NUM_LAYERS)+\"_nNeurons\"+str(NUM_NEURONS)+\".hdf5\"\n",
        "ext = f\".Flatten.l2.{str(l2_val)}.run_1\" # run_1 run_2 .DropAfter .momentum0.9\n",
        "#'''\n",
        "checkpointer_name  = \"weights.\"+dataset+\".pad\"+str(pad)+\".\"+impl_type+\".wInit.\"+str(init_weights)+\".TrainableAfter.\"+str(pointTrainableAfter)+\\\n",
        "                     modelExt+\".actF.\"+ACTIVATION_FUNCTION+\".opt.\"+OPTIMIZER+\".drop.\"+str(DROPOUT)+\".batch\"+str(BATCH_SIZE)+ext+\".hdf5\"\n",
        "log_name = \"log.\"+checkpointer_name[8:-5]+\".log\"\n",
        "\n",
        "print('checkpointer_name =', checkpointer_name)\n",
        "print('log_name =', log_name)\n",
        "#'''"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpointer_name = weights.MalayaKew.D2.TTV.rgb.256p.DataAug.DataFlow.pad0.TL.3D.DenseNet201.wInit.imagenet.TrainableAfter.allDefault.Dense.1024.1024.2048.actF.elu.opt.Adam.drop.0.5.batch16.Flatten.l2.0.001.run_1.hdf5\n",
            "log_name = log.MalayaKew.D2.TTV.rgb.256p.DataAug.DataFlow.pad0.TL.3D.DenseNet201.wInit.imagenet.TrainableAfter.allDefault.Dense.1024.1024.2048.actF.elu.opt.Adam.drop.0.5.batch16.Flatten.l2.0.001.run_1.log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcB3WVaWO6BV",
        "outputId": "e60a905f-91ef-4c24-d3cf-1892f41ff122"
      },
      "source": [
        "train_generator.image_shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyK6ZbJOOsjV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a949aa-0d47-4824-93c9-8c50eeb65a89"
      },
      "source": [
        "#'''\n",
        "#base_model=DenseNet121(weights=None, include_top=False, input_shape=np_train_dataset2.shape[1:]) # `None` (random initialization)\n",
        "#base_model=ResNet152V2(weights=None, include_top=False, input_shape=np_train_dataset2.shape[1:])\n",
        "# ResNet152V2 ResNet50 ResNet101 ResNet152 DenseNet201 InceptionV3 Xception NASNetLarge 'imagenet' ResNet152V2 DenseNet121\n",
        "#inputs = Input(final_train_imageset.shape[1:])\n",
        "#x = ZeroPadding2D(padding=(pad,pad))(inputs)\n",
        "#base_model=tf.keras.applications.ResNet50(weights=init_weights, include_top=False, input_tensor=x)\n",
        "base_model=tf.keras.applications.DenseNet201(weights=init_weights, include_top=False, input_shape=train_generator.image_shape)\n",
        "x=base_model.output\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "#'''\n",
        "x = Dense(1024, kernel_regularizer=tf.keras.regularizers.l2(l2_val), activation=ACTIVATION_FUNCTION)(x)\n",
        "#x_copy = x\n",
        "x = Dropout(DROPOUT)(x)\n",
        "x = Dense(1024, kernel_regularizer=tf.keras.regularizers.l2(l2_val), activation=ACTIVATION_FUNCTION)(x)\n",
        "x = Dropout(DROPOUT)(x)\n",
        "x = Dense(2048, kernel_regularizer=tf.keras.regularizers.l2(l2_val), activation=ACTIVATION_FUNCTION)(x)\n",
        "x = Dropout(DROPOUT)(x)\n",
        "#x = Add()([x,x_copy])\n",
        "#'''\n",
        "outputs=Dense(num_classes,activation='softmax')(x)\n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=outputs)\n",
        "#model.summary()\n",
        "#'''"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74842112/74836368 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "WgomlDGDqn6-",
        "outputId": "570418c1-f825-464e-a26c-0aea7c719c9f"
      },
      "source": [
        "'''\n",
        "tf.keras.utils.plot_model(\n",
        "    model, to_file='model.png', show_shapes=True, show_dtype=False,\n",
        "    show_layer_names=True, rankdir='TB', expand_nested=True, dpi=64\n",
        ")\n",
        "#'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ntf.keras.utils.plot_model(\\n    model, to_file='model.png', show_shapes=True, show_dtype=False,\\n    show_layer_names=True, rankdir='TB', expand_nested=True, dpi=64\\n)\\n#\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozx7Z-ZiUE-2",
        "outputId": "bc235f26-32f9-47ba-bee8-a18bd54f94e3"
      },
      "source": [
        "count_trainable = 0\n",
        "count_non_trainable = 0\n",
        "\n",
        "#'''\n",
        "if pointTrainableAfter == \"allDefault\":\n",
        "    for layer in model.layers:\n",
        "        layer.trainable=True\n",
        "        count_trainable += 1\n",
        "elif pointTrainableAfter > 0:\n",
        "    for layer in model.layers[:pointTrainableAfter]: # [:-pointTrainableAfter]\n",
        "        layer.trainable=False\n",
        "        count_non_trainable += 1\n",
        "    for layer in model.layers[pointTrainableAfter:]: # [-pointTrainableAfter:]\n",
        "        layer.trainable=True\n",
        "        count_trainable += 1\n",
        "#'''\n",
        "\n",
        "'''\n",
        "for layer in model.layers:\n",
        "    layer.trainable=True\n",
        "    count_trainable += 1\n",
        "#'''\n",
        "\n",
        "print(\"count_non_trainable =\", count_non_trainable)\n",
        "print(\"count_trainable =\", count_trainable)\n",
        "print(\"Total number of layers =\", count_non_trainable+count_trainable)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count_non_trainable = 0\n",
            "count_trainable = 715\n",
            "Total number of layers = 715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "aqwYD5TGPxyV",
        "outputId": "5f7c643d-529f-415f-8dc4-568350c25498"
      },
      "source": [
        "'''\n",
        "checkpointer_name  = \"weights.\"+dataset+\".pad\"+str(pad)+\".\"+impl_type+\".wInit.\"+str(init_weights)+\".TrainableAfter.\"+str(pointTrainableAfter)+\\\n",
        "                     modelExt+\".opt.\"+OPTIMIZER+\".drop.\"+str(DROPOUT)+\".batch\"+str(BATCH_SIZE)+ext+\".hdf5\"\n",
        "log_name = \"log.\"+checkpointer_name[8:-5]+\".log\"\n",
        "\n",
        "print('checkpointer_name =', checkpointer_name)\n",
        "print('log_name =', log_name)\n",
        "#'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ncheckpointer_name  = \"weights.\"+dataset+\".pad\"+str(pad)+\".\"+impl_type+\".wInit.\"+str(init_weights)+\".TrainableAfter.\"+str(pointTrainableAfter)+                     modelExt+\".opt.\"+OPTIMIZER+\".drop.\"+str(DROPOUT)+\".batch\"+str(BATCH_SIZE)+ext+\".hdf5\"\\nlog_name = \"log.\"+checkpointer_name[8:-5]+\".log\"\\n\\nprint(\\'checkpointer_name =\\', checkpointer_name)\\nprint(\\'log_name =\\', log_name)\\n#'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T7w_lC1QCPh",
        "outputId": "7e5e866b-b38a-418a-f4bb-87d88353f021"
      },
      "source": [
        "# \"RMSProp\" \"SGD\" \"Adam\" \"Adamax\" \"Adadelta\" \"Adagrad\" \"SGD\"\n",
        "#optimizer = tf.keras.optimizers.RMSprop(lr = LEARNING_RATE, epsilon=EPSILON)\n",
        "\n",
        "if OPTIMIZER == \"RMSProp\":\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate = LEARNING_RATE, epsilon=EPSILON)\n",
        "elif OPTIMIZER == \"Adam\":\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = LEARNING_RATE, epsilon=EPSILON, beta_1=0.9, beta_2=0.999)\n",
        "elif OPTIMIZER == \"Adamax\":\n",
        "    optimizer = tf.keras.optimizers.Adamax(learning_rate = LEARNING_RATE, epsilon=EPSILON, beta_1=0.9, beta_2=0.999)\n",
        "elif OPTIMIZER == \"Adadelta\":\n",
        "    optimizer = tf.keras.optimizers.Adadelta(learning_rate = LEARNING_RATE, epsilon=EPSILON, rho=0.95)\n",
        "elif OPTIMIZER == \"Adagrad\":\n",
        "    optimizer = tf.keras.optimizers.Adagrad(learning_rate = LEARNING_RATE, epsilon=EPSILON, initial_accumulator_value=0.1)\n",
        "elif OPTIMIZER == \"SGD\":\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate = LEARNING_RATE, momentum=0.9)\n",
        "\n",
        "model.compile(\n",
        "    #optimizer=OPTIMIZER,\n",
        "    optimizer=optimizer,\n",
        "    loss=LOSS,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"OPTIMIZER =\", OPTIMIZER)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OPTIMIZER = Adam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdySVEG3QCpv"
      },
      "source": [
        "# save the best model with least validation loss\n",
        "checkpointer = ModelCheckpoint(filepath = work_dir+checkpointer_name, \n",
        "                               #monitor='val_accuracy',\n",
        "                               monitor='val_loss',\n",
        "                               save_weights_only=False,  \n",
        "                               mode='auto', \n",
        "                               verbose = 0, # 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
        "                               save_best_only =False\n",
        "                               )\n",
        "checkpointer_best = ModelCheckpoint(filepath = work_dir+\"best_\"+checkpointer_name, \n",
        "                                    monitor='val_loss', \n",
        "                                    save_weights_only=False,\n",
        "                                    mode='auto',  \n",
        "                                    verbose = 1, \n",
        "                                    save_best_only = True\n",
        "                                    )\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=early_stop_after_epochs)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq3iXmYXQHNL",
        "outputId": "b6e17b58-0332-4b58-c701-7c494ed89fa5"
      },
      "source": [
        "'''\n",
        "if 'count_no_improvement' not in globals():\n",
        "    count_no_improvement = 0\n",
        "    print(\"count_no_improvement =\", count_no_improvement)\n",
        "#'''\n",
        "'''\n",
        "count_no_improvement = 0\n",
        "epoch_initial = False\n",
        "#'''\n",
        "min_delta = 0.0009\n",
        "print(\"count_no_improvement =\", count_no_improvement)\n",
        "\n",
        "def checkBestPerformance(epoch, logs):\n",
        "    save_filepath = work_dir+\"best_\"+checkpointer_name\n",
        "\n",
        "    global epoch_initial\n",
        "    if epoch_initial == True:\n",
        "        epoch_initial = False\n",
        "        model.save(filepath = save_filepath)\n",
        "        print(\". Model saved!\")\n",
        "\n",
        "    elif epoch_initial == False:\n",
        "        global count_no_improvement\n",
        "\n",
        "        log_data = pd.read_csv(work_dir+log_name, sep=',', usecols=['val_loss', 'val_accuracy'], engine='python')\n",
        "        min_val_loss = float(str(min(log_data.val_loss.values))[:6])\n",
        "        max_val_acc = float(str(max(log_data.val_accuracy.values))[:6])\n",
        "\n",
        "        current_val_acc = float(str(logs['val_accuracy'])[:6])\n",
        "        current_val_loss = float(str(logs['val_loss'])[:6])\n",
        "\n",
        "        if (current_val_loss < min_val_loss) and (abs(current_val_loss-min_val_loss) >= min_delta):\n",
        "            count_no_improvement = 0\n",
        "            model.save(filepath = save_filepath)\n",
        "            print(\"\\nval_loss decreased from\",min_val_loss,\" to\",current_val_loss,\"( val_accuracy =\",current_val_acc,\").\")\n",
        "\n",
        "        elif (current_val_loss==min_val_loss) and (current_val_acc>max_val_acc):\n",
        "            count_no_improvement = 0\n",
        "            model.save(filepath = save_filepath)\n",
        "            print(\"\\nval_accuracy increased to\", current_val_acc, \".\")\n",
        "\n",
        "        else:\n",
        "            count_no_improvement += 1\n",
        "            print(\". count_no_improvement =\", count_no_improvement)\n",
        "\n",
        "        if count_no_improvement >= early_stop_after_epochs:\n",
        "            global list_callbacks\n",
        "            del list_callbacks, count_no_improvement\n",
        "            #print(\"count_no_improvement =\", count_no_improvement, \"... list_callbacks =\", list_callbacks)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count_no_improvement = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYewyuDiREFZ",
        "outputId": "049c5295-f3bf-44b6-abcf-c52a1265d324"
      },
      "source": [
        "epochs_completed = 0\n",
        "list_callbacks = []\n",
        "csv_logger = CSVLogger(work_dir+log_name, separator=',', append=True)\n",
        "\n",
        "#if 'list_callbacks' in globals():\n",
        "#    del list_callbacks\n",
        "\n",
        "try:\n",
        "    log_data = pd.read_csv(work_dir+log_name, sep=',', usecols=['epoch'], engine='python')\n",
        "    epochs_completed = log_data.shape[0]\n",
        "\n",
        "    #if epochs_completed > 0:\n",
        "    model = load_model(work_dir+checkpointer_name)\n",
        "    list_callbacks = [checkpointer, LambdaCallback(on_epoch_end=checkBestPerformance), csv_logger]\n",
        "    print(\"epochs_completed =\", epochs_completed)\n",
        "\n",
        "except Exception as error:\n",
        "    if epochs_completed == 0:\n",
        "        # list_callbacks = [checkpointer, checkpointer_best, csv_logger, early_stopping] \n",
        "        list_callbacks = [checkpointer, LambdaCallback(on_epoch_end=checkBestPerformance), csv_logger]\n",
        "        print(\"epochs_completed =\", epochs_completed)\n",
        "    elif epochs_completed > 0:\n",
        "        print(error)\n",
        "\n",
        "print('checkpointer_name =', checkpointer_name)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs_completed = 5\n",
            "checkpointer_name = weights.MalayaKew.D2.TTV.rgb.256p.DataAug.DataFlow.pad0.TL.3D.DenseNet201.wInit.imagenet.TrainableAfter.allDefault.Dense.1024.1024.2048.actF.elu.opt.Adam.drop.0.5.batch16.Flatten.l2.0.001.run_1.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JKqrHnwRGGz",
        "outputId": "4c62e037-9e9e-485e-bf90-986e99180614"
      },
      "source": [
        "print('checkpointer_name =', checkpointer_name)\n",
        "print(\"Previously completed epochs =\", epochs_completed)\n",
        "print(\"count_no_improvement =\", count_no_improvement, \"\\n\")\n",
        "\n",
        "#'''\n",
        "try:\n",
        "    start_time = time.time()\n",
        "    history = model.fit(train_generator, \n",
        "                        steps_per_epoch=total_train_data // BATCH_SIZE,\n",
        "                        shuffle=True, \n",
        "                        epochs = NUM_EPOCHS - epochs_completed, \n",
        "                        validation_data=val_generator,\n",
        "                        validation_steps=total_val_data // BATCH_SIZE,\n",
        "                        callbacks=list_callbacks\n",
        "                        )\n",
        "    elapsed_time = time.time() - start_time \n",
        "    print(\"\\nTime elapsed: \", elapsed_time)\n",
        "\n",
        "except Exception as error:\n",
        "    print(\"\\nError:\", error)\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpointer_name = weights.MalayaKew.D2.TTV.rgb.256p.DataAug.DataFlow.pad0.TL.3D.DenseNet201.wInit.imagenet.TrainableAfter.allDefault.Dense.1024.1024.2048.actF.elu.opt.Adam.drop.0.5.batch16.Flatten.l2.0.001.run_1.hdf5\n",
            "Previously completed epochs = 5\n",
            "count_no_improvement = 0 \n",
            "\n",
            "Epoch 1/20\n",
            "1735/1735 [==============================] - 12468s 7s/step - loss: 3.4855 - accuracy: 0.9123 - val_loss: 3.5193 - val_accuracy: 0.9065\n",
            ". Model saved!\n",
            "Epoch 2/20\n",
            "1735/1735 [==============================] - 798s 459ms/step - loss: 3.3587 - accuracy: 0.9327 - val_loss: 3.5061 - val_accuracy: 0.9049\n",
            "\n",
            "val_loss decreased from 3.5192  to 3.5061 ( val_accuracy = 0.9048 ).\n",
            "Epoch 3/20\n",
            "1735/1735 [==============================] - 789s 454ms/step - loss: 3.2490 - accuracy: 0.9465 - val_loss: 3.3889 - val_accuracy: 0.9160\n",
            "\n",
            "val_loss decreased from 3.5061  to 3.3888 ( val_accuracy = 0.916 ).\n",
            "Epoch 4/20\n",
            "1735/1735 [==============================] - 778s 447ms/step - loss: 3.1510 - accuracy: 0.9577 - val_loss: 3.5705 - val_accuracy: 0.8957\n",
            ". count_no_improvement = 1\n",
            "Epoch 5/20\n",
            "1735/1735 [==============================] - 775s 446ms/step - loss: 3.0737 - accuracy: 0.9638 - val_loss: 3.2725 - val_accuracy: 0.9230\n",
            "\n",
            "val_loss decreased from 3.3888  to 3.2724 ( val_accuracy = 0.9229 ).\n",
            "Epoch 6/20\n",
            "1735/1735 [==============================] - 780s 449ms/step - loss: 2.9916 - accuracy: 0.9688 - val_loss: 3.1348 - val_accuracy: 0.9382\n",
            "\n",
            "val_loss decreased from 3.2724  to 3.1348 ( val_accuracy = 0.9382 ).\n",
            "Epoch 7/20\n",
            "1735/1735 [==============================] - 795s 457ms/step - loss: 2.9189 - accuracy: 0.9717 - val_loss: 3.0818 - val_accuracy: 0.9411\n",
            "\n",
            "val_loss decreased from 3.1348  to 3.0818 ( val_accuracy = 0.9411 ).\n",
            "Epoch 8/20\n",
            "1735/1735 [==============================] - 783s 451ms/step - loss: 2.8346 - accuracy: 0.9764 - val_loss: 3.1365 - val_accuracy: 0.9288\n",
            ". count_no_improvement = 1\n",
            "Epoch 9/20\n",
            "1735/1735 [==============================] - 775s 446ms/step - loss: 2.7565 - accuracy: 0.9784 - val_loss: 3.0068 - val_accuracy: 0.9282\n",
            "\n",
            "val_loss decreased from 3.0818  to 3.0067 ( val_accuracy = 0.9282 ).\n",
            "Epoch 10/20\n",
            "1735/1735 [==============================] - 778s 448ms/step - loss: 2.6764 - accuracy: 0.9815 - val_loss: 2.8901 - val_accuracy: 0.9416\n",
            "\n",
            "val_loss decreased from 3.0067  to 2.8901 ( val_accuracy = 0.9415 ).\n",
            "Epoch 11/20\n",
            "1735/1735 [==============================] - 785s 452ms/step - loss: 2.5952 - accuracy: 0.9833 - val_loss: 2.8285 - val_accuracy: 0.9387\n",
            "\n",
            "val_loss decreased from 2.8901  to 2.8284 ( val_accuracy = 0.9386 ).\n",
            "Epoch 12/20\n",
            "1735/1735 [==============================] - 785s 451ms/step - loss: 2.5198 - accuracy: 0.9836 - val_loss: 2.8163 - val_accuracy: 0.9365\n",
            "\n",
            "val_loss decreased from 2.8284  to 2.8163 ( val_accuracy = 0.9364 ).\n",
            "Epoch 13/20\n",
            "1735/1735 [==============================] - 776s 447ms/step - loss: 2.4381 - accuracy: 0.9864 - val_loss: 2.6311 - val_accuracy: 0.9468\n",
            "\n",
            "val_loss decreased from 2.8163  to 2.631 ( val_accuracy = 0.9467 ).\n",
            "Epoch 14/20\n",
            "1735/1735 [==============================] - 777s 447ms/step - loss: 2.3565 - accuracy: 0.9879 - val_loss: 2.5344 - val_accuracy: 0.9500\n",
            "\n",
            "val_loss decreased from 2.631  to 2.5344 ( val_accuracy = 0.9499 ).\n",
            "Epoch 15/20\n",
            "1735/1735 [==============================] - 775s 447ms/step - loss: 2.2747 - accuracy: 0.9884 - val_loss: 2.6055 - val_accuracy: 0.9345\n",
            ". count_no_improvement = 1\n",
            "Epoch 16/20\n",
            "1735/1735 [==============================] - 766s 442ms/step - loss: 2.2001 - accuracy: 0.9886 - val_loss: 2.4110 - val_accuracy: 0.9461\n",
            "\n",
            "val_loss decreased from 2.5344  to 2.4109 ( val_accuracy = 0.946 ).\n",
            "Epoch 17/20\n",
            "1735/1735 [==============================] - 771s 444ms/step - loss: 2.1177 - accuracy: 0.9898 - val_loss: 2.3523 - val_accuracy: 0.9448\n",
            "\n",
            "val_loss decreased from 2.4109  to 2.3522 ( val_accuracy = 0.9447 ).\n",
            "Epoch 18/20\n",
            "1735/1735 [==============================] - 787s 454ms/step - loss: 2.0371 - accuracy: 0.9911 - val_loss: 2.2281 - val_accuracy: 0.9501\n",
            "\n",
            "val_loss decreased from 2.3522  to 2.2281 ( val_accuracy = 0.9501 ).\n",
            "Epoch 19/20\n",
            "1735/1735 [==============================] - 785s 453ms/step - loss: 1.9583 - accuracy: 0.9907 - val_loss: 2.1859 - val_accuracy: 0.9506\n",
            "\n",
            "val_loss decreased from 2.2281  to 2.1858 ( val_accuracy = 0.9505 ).\n",
            "Epoch 20/20\n",
            " 169/1735 [=>............................] - ETA: 12:18 - loss: 1.9101 - accuracy: 0.9926"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJsgsZFzQCs2"
      },
      "source": [
        "# weights.MalayaKew.D2.TTV.rgb.256p.DataAug.DataFlow.pad0.TL.3D.DenseNet201.wInit.imagenet.TrainableAfter.allDefault.Dense.1024.1024.2048.actF.elu.opt.Adam.drop.0.5.batch16.Flatten.l2.0.001.run_1.hdf5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_xKnoFvFQ4F"
      },
      "source": [
        "'''\n",
        "Record: : (99.5%)\n",
        ";\n",
        "---\n",
        "\n",
        "'''\n",
        "'''\n",
        "csv_logger = CSVLogger(work_dir+log_name, separator=',', append=True)\n",
        "log_data = pd.read_csv(work_dir+log_name, sep=',', usecols=['epoch'], engine='python')\n",
        "epochs_completed = log_data.shape[0]\n",
        "\n",
        "result = model.evaluate(test_generator, steps=total_test_data // BATCH_SIZE)\n",
        "print(\"Test Acc: {}, Test Loss: {}: ep{}, {}\\n\".format(round(result[1],4), round(result[0],4), epochs_completed, checkpointer_name))\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQM7JieEFQ1G"
      },
      "source": [
        "#checkpointer_name = \"weights.Fashion.DenseNet121.wInit.None.TrainableAfterallDefault.opt.SGD.drop.0.0.batch32.Flatten.run_1.hdf5\"\n",
        "model_loaded = load_model(work_dir+\"best_\"+checkpointer_name)\n",
        "print(\"Loaded \"+work_dir+\"best_\"+checkpointer_name+\".\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chvVsOEgRfsO"
      },
      "source": [
        "'''\n",
        "Record: Plant_Leaf_MalayaKew_MK_impl_2_TrainTesVal_Original_RGB_Dense201_Custom_withImageNet_DataFlow: (99.5%)\n",
        ";\n",
        "---\n",
        "Test Acc: 0.9819, Test Loss: 2.2513: ep19, best_weights.MalayaKew.D2.TTV.rgb.256p.DataFlow.pad0.TL.3D.DenseNet201.wInit.imagenet.TrainableAfter.allDefault.Dense.1024.1024.2048.actF.elu.opt.Adam.drop.0.5.batch16.Flatten.l2.0.001.run_1.hdf5\n",
        "\n",
        "'''\n",
        "'''\n",
        "csv_logger = CSVLogger(work_dir+log_name, separator=',', append=True)\n",
        "log_data = pd.read_csv(work_dir+log_name, sep=',', usecols=['epoch'], engine='python')\n",
        "epochs_completed = log_data.shape[0]\n",
        "#'''\n",
        "\n",
        "result2 = model_loaded.evaluate(test_generator, steps=total_test_data // BATCH_SIZE)\n",
        "#print(\"nLayers: {}, nNeurons: {}, DROPOUT: {}, Test Acc: {}, Test Loss: {}\".format(NUM_LAYERS, NUM_NEURONS, DROPOUT, round(result2[1], 4), round(result2[0], 4)))\n",
        "print(\"Test Acc: {}, Test Loss: {}: ep{}, {}\\n\".format(round(result2[1],4), round(result2[0],4), epochs_completed, \"best_\"+checkpointer_name))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1GzwpODRlRf"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open(work_dir+'Records.csv', \"a\") as fp:\n",
        "    wr = csv.writer(fp, dialect='excel')\n",
        "    try:\n",
        "        wr.writerow([checkpointer_name[8:-5], round(result2[1], 4), round(result2[0], 4), elapsed_time])\n",
        "    except:\n",
        "        wr.writerow([checkpointer_name[8:-5], round(result2[1], 4), round(result2[0], 4)])\n",
        "print(\"Saved results.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv35-hm1Rfv5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r41Tx24EuA8A"
      },
      "source": [
        "#Confution Matrix and Classification Report\n",
        "#'''\n",
        "Y_pred = model_loaded.predict_generator(test_generator, verbose=1)\n",
        "#'''\n",
        "#'''\n",
        "save_predictions_filename = f\"Y_pred.{checkpointer_name[8:-5]}\"\n",
        "np.save(f\"{work_dir}{save_predictions_filename}\", Y_pred, allow_pickle=True)\n",
        "print(f\"Saved: {work_dir}{save_predictions_filename}\")\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCOqGtOtSVG5"
      },
      "source": [
        "'''\n",
        "save_predictions_filename = f\"Y_pred.{checkpointer_name[8:-5]}\"\n",
        "np.save(f\"{work_dir}{save_predictions_filename}\", Y_pred, allow_pickle=True)\n",
        "print(f\"Saved: {work_dir}{save_predictions_filename}\")\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5DLKM2YTGiR"
      },
      "source": [
        "Y_pred_loaded = np.load(f\"{work_dir}{save_predictions_filename}.npy\", allow_pickle=True)\n",
        "print(f\"Y_pred_loaded.shape = {Y_pred_loaded.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKVblYYLTR8O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPVcI8W8uVxT"
      },
      "source": [
        "y_pred = np.argmax(Y_pred_loaded, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWjMUxOC_idw"
      },
      "source": [
        "y_true = test_generator.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AnENPzD_XCi"
      },
      "source": [
        "list_class_names_in_generator = list(test_generator.class_indices.keys())\n",
        "list_class_names_in_generator[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c1QqkvSB4rw"
      },
      "source": [
        "list_y_true_rearranged = []\n",
        "list_y_pred_rearranged = []\n",
        "\n",
        "for true_class,pred_class in zip(y_true,y_pred):\n",
        "    y_true_rearranged = int(list_class_names_in_generator[true_class][5:])\n",
        "    y_pred_rearranged = int(list_class_names_in_generator[pred_class][5:])\n",
        "\n",
        "    list_y_true_rearranged.append(y_true_rearranged)\n",
        "    list_y_pred_rearranged.append(y_pred_rearranged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twUaOkzO_lYu"
      },
      "source": [
        "np_y_true_rearranged = np.array(list_y_true_rearranged)\n",
        "np_y_pred_rearranged = np.array(list_y_pred_rearranged)\n",
        "\n",
        "print(f\"np_y_true_rearranged.shape = {np_y_true_rearranged.shape}\")\n",
        "print(f\"np_y_pred_rearranged.shape = {np_y_pred_rearranged.shape}\")\n",
        "print(f\"np_y_true_rearranged: {np_y_true_rearranged}\")\n",
        "print(f\"np_y_pred_rearranged: {np_y_pred_rearranged}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxgBOkM5Es08"
      },
      "source": [
        "print(f\"np_y_true_rearranged.shape = {np_y_true_rearranged.shape}\\n\")\n",
        "\n",
        "index = -5\n",
        "print(f\"y_true[{index}:] = {y_true[index:]}\")\n",
        "print(f\"y_pred[{index}:] = {y_pred[index:]}\\n\")\n",
        "print(f\"np_y_true_rearranged[{index}:] = {np_y_true_rearranged[index:]}\")\n",
        "print(f\"np_y_pred_rearranged[{index}:] = {np_y_pred_rearranged[index:]}\\n\")\n",
        "print(f\"np.unique(np_y_true_rearranged) = {np.unique(np_y_true_rearranged)}\")\n",
        "print(f\"np.unique(np_y_pred_rearranged) = {np.unique(np_y_pred_rearranged)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo2maYGREHa1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATQ8O5enuJcA"
      },
      "source": [
        "conf_matrix = sklearn.metrics.confusion_matrix(np_y_true_rearranged, np_y_pred_rearranged)\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWt92DPh8BIG"
      },
      "source": [
        "#plt.figure(figsize = (30,30))\n",
        "plt.matshow(conf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYbVekfx9Qk-"
      },
      "source": [
        "df_conf_matrix = pd.DataFrame(conf_matrix, index = [f\"Class {i+1}\" for i in range(num_classes)],\n",
        "                  columns = [f\"Class {i+1}\" for i in range(num_classes)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhhb_ykf7mGr"
      },
      "source": [
        "title = \"Confusion matrix for \"+dataset+\" \"+impl_type+\"\\n\"\n",
        "plt.figure(figsize = (30,15))\n",
        "plt.title(title)\n",
        "sn.heatmap(df_conf_matrix, annot=True)\n",
        "\n",
        "img_path = work_dir+'Images/conf_matrix_'+checkpointer_name[8:-5]+'.png'\n",
        "plt.savefig(img_path, dpi=600)\n",
        "print(f\"img_path = {img_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyvlKAMW-q4-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgY4v21DyQwL"
      },
      "source": [
        "#Confution Matrix and Classification Report\n",
        "'''\n",
        "Y_pred = model_loaded.predict_generator(final_test_imageset, len(final_test_imageset))\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(sklearn.metrics.confusion_matrix(np_test_label, y_pred))\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5j7b3KcRvwj"
      },
      "source": [
        "# Precision [TP/TP+FP] = The ratio of correctly predicted positive observations to the total predicted positive observations.\n",
        "# Recall (Sensitivity) [TP/TP+FN] = The ratio of correctly predicted positive observations to the all observations in actual class - 'yes'.\n",
        "# F1 score [F1 Score = 2*(Recall * Precision) / (Recall + Precision)] = The weighted average of Precision and Recall.\n",
        "# Support = The number of samples of the true response that lie in that class.\n",
        "'''\n",
        "print('Classification Report:')\n",
        "print(sklearn.metrics.classification_report(test_generator.classes, y_pred))\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTwSA-kRYavk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaZZkLXW6Vb8"
      },
      "source": [
        "test_generator.class_indices.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceGRitu9RvzV"
      },
      "source": [
        "#'''\n",
        "print('Classification Report')\n",
        "print(sklearn.metrics.classification_report(test_generator.classes, y_pred, target_names=test_generator.class_indices.keys()))\n",
        "#'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujLQjTf2Rv11"
      },
      "source": [
        "log_data = pd.read_csv(work_dir+log_name, sep=',', engine='python') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To55jgGSRv4a"
      },
      "source": [
        "# Getting the model history keys \n",
        "#history.history.keys()\n",
        "log_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aytAYSJ4Rv7T"
      },
      "source": [
        "# plot the training artifacts\n",
        "title = \"Val loss for \"+dataset+\" \"+impl_type+\"\\n\"\n",
        "\n",
        "plt.plot(log_data['loss'])\n",
        "plt.plot(log_data['val_loss'])\n",
        "plt.title(title)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss','val_loss'], loc = 'best')\n",
        "plt.grid(b=True, which='major', axis='both')\n",
        "\n",
        "img_path = work_dir+'Images/vLoss_'+checkpointer_name[8:-5]+'.png'\n",
        "plt.savefig(img_path, dpi=600)\n",
        "plt.show()\n",
        "print('img_path =', img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUq1WaElRv-M"
      },
      "source": [
        "title = \"Val acc for \"+dataset+\" \"+impl_type+\"\\n\"\n",
        "\n",
        "plt.plot(log_data['accuracy'])\n",
        "plt.plot(log_data['val_accuracy'])\n",
        "plt.title(title)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_accuracy','val_accuracy'], loc = 'best')\n",
        "plt.grid(b=True, which='major', axis='both')\n",
        "\n",
        "img_path = work_dir+'Images/vAcc_'+checkpointer_name[8:-5]+'.png'\n",
        "plt.savefig(img_path, dpi=600)\n",
        "plt.show()\n",
        "print('img_path =', img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4msuVKMSk8E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}